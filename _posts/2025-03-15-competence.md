---
layout: post
author: Alex
title: Are we putting competence aside?
draft: true
---

Let me start this out by saying we live in a very weird time. One could say we live in a privileged time where before people who were software developers needed to really know their craft because they couldn't just prompt or look at Stack Overflow posts about their problems. In fact, there are people still alive that programmed in their undergrad using punch cards, where debugging was at least a day in duration. Yet we have so much information at our disposal, plenty documentation and when there is none or its poor we can just hit a chatbot and get new documentation tailored to our question. And with this I question what will we do collectively because whenever we have something that requires no effort to use, we lean on it. If we can offload some of our processing power to it, we do.

Thinking back it wasn't too long ago that I had to memorize phone numbers in case I wanted to call someone because I didn't grow up having a cellphone till I was a teenager and even then it could only hold so many contacts. After a few years I no longer remembered any telephone numbers except my home phone number and my Grandmother's. Now I only know one. Why? Because why would I need to remember any of these numbers, its all a few taps away and instead of having to remember the number, I can just navigate to the contact name, which is easier to remember, and tap call. Basically, technology has made it so easy (via abstraction?, convenience?) to just remember a name and the device will do the translation to the number. Now that I think of it, no different than what Domain Name System (DNS) did for web addresses. Its abstracted away and something easier replaced it.

Now as I mentioned before with the recent advances to Large Language Models (LLM's) and Chatbots we have more access to information than ever before and what novel is it can generate information too. Something we didn't have before. Say you are dealing with a pesky API that has poor documentation, well if the API is public you can fire up a chatbot and have it give you examples. Hey the examples are in Python but you have a Go codebase, no problem! Just tell the bot to change it Go and presto! You now have code you might be able to copy and paste and tweak (right!??). This is amazing but also a bit terrifying because if the solution is so close, or in many cases, the illusion of the solution is very close, what incentive do you have to dive deep? If I am facing a gnarly problem with conflicting NPM packages because I decided to install isDivisibleByTwo? and I can just ask the LLM to find a list of possible solutions when will I devise this list in my head from experience? Because most talented programmers learn from experience, especially painful ones. You don't "git gud" by prompting. You get better by having time in the saddle and strugglig with problems. I fear LLM's and our dependence and thier integration into dev tooling will hinder this. Seeing a Jr dev go straight to ChatGPT for a solution instead of working out core problem and taking a moment to just evaluate what can be done is a worrying sight. What will these developers do during an outage of internet or the service? Are we gonna see Slack messages of: "Im out today, ChatGippity is down" I hope not.

Imagine that being your daily flow for programming anything. How would you approach each line? How much would you revise your code? How in depth would you check each function call? I'd bet if we were in this time, most of us would pour more thought and carefulness into the code we write because if the developer feedback loop is a day at the fastest (following the punch card example) we would not only triple check each piece of syntax but the underlying logic of our code. And its not to say we can't do that today with our tools. Of course we can! And we can do it incrededibly faster but why would you? We live in a time where even building/compiling your code is seen as a waste of time or an obstacle to the developer feedback loop and things like hot module reloading have been implemente so that as soon as you save, your changes are on display and you can evaluate. It's here that I think we have the first pitfall to achieving competence. Because its very easy, and tempting too, to sling some code in the editor and just "evaluate it" and if it doesn't work then you do some small thinking and repeat again. I don't think this is optimal. From my experience, when I do this approach I kind of end up monkey typing my way to a solution. One I always end up refactoring but its still a monkey type journey. Just as an example, how many times have you ever found yourself in a TS codebase, just mokeying around with types so the TS server is happy and you couldn't be bothered to actually look at the types and why they are being flagged? It could just be me, but I don't think I am the only one. And I don't want to be mistaken that I am advocating we need to sit down and think of our code and ponder on it like some philosopher till it is perfect. That end is also problematic because I think it leads you down the path of premature optimization and "cleverness". The type of thinking that has you writing a custom JSON parser because you can "forsee" the available options as becoming "problematic" down the line. I think we need something in the middle like a balancing act in order for us to build competence. We need the feedback loop to be short as possible but still have enough roughness to keep monkey type behavior away.

In the same vein, I think ChatGPT and of its competitors offer similar benefits and drawbacks. If getting the solution is a simple prompt away what incentive is there for you to sit down, understand the problem and come up with a solution? I feel its all too easy to just let the AI do it. "Just offload to the AI, you can do 10x more if you do so" is what so many people believe but I think relying on AI is not going to help. First I think its a classic exchange of quick gains at the expense of long term pain/problems. You get your answers quickly, sure, but you also don't get solutions with very good context and the solutions that this AI's throwout are based on the information it has consumed. If you have some novel problem with very little information out there, well good luck. The AI isn't really going to help you, if you are someone like the Primeagen, TJ, Theo, well you will shrug it off and continue to tackle the problem but for others that rely on these technologies they might as well closed their Macbooks and take a nap because they don't have the skillset to actually push through, at least not without considerable effort in the process. And its not just new developers at stake here, even seasoned dev can acquire the Copilot pause. I even found myself affected from using Copilot where I forgot mid-interview how to write a Map in Typescript. I could not remember the syntax at all depite having seen it being autocompleted dozens of times in the week before. Which is why I have pose the question to myself and to you the reader, what are we giving in exchange for using these tools and relying on them? Does it really make you a better dev? Are you really more productive across the board? I find it really isn't helping me. Sure if I need to look something up, or I need a quick demo, tutorial or just a summary, its great. But if what I am working on is a bit more ambitious or novel, I find it leads me astray more often than not and cause problems I am not aware of until much later.

Which leads me to another thought and that is to be becareful of what tools we bring in to our toolbox. But that is a post in and of itself.
